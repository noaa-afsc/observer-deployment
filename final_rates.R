# Rates for 2024 Final ADP

# Author: Geoff Mayhew
# Start Date: 13 Nov 2024

#======================================================================================================================#
# Preparation ----------------------------------------------------------------------------------------------------------
#======================================================================================================================#

#===================#
## Load Packages ----
#===================#

library(data.table)         # Data wrangling
library(ggplot2)            # Plotting
library(grid)               # For unit.pmax  to get widths of grobs so that plots have matching dimensions
library(gridExtra)          # For arrangeGrob to combine plots
library(sf)                 # Spatial analyses
library(flextable)          # For print-ready tables
library(officer)            # For additional flextable formatting options such as fp_border
library(dplyr)              # For piping and handling sf objects
library(readxl)             # For read_xlsx

#=============================#
## Load data and data prep ----
#=============================#

# Fishing effort data from 2018 to 2023
# Generated by /analyses/spatiotemporal_boxes/data_prep.R
# In Vision 2024 ADP/Data/Final ADP Outputs folder:   https://drive.google.com/file/d/1Iet_Fh_8u06UcGwCrZGGWTARpvAAjzky/view?usp=drive_link
load("analyses/allocation_evaluation/data_prep_final_2024.Rdata")       # loads pc_effort_dt, trips_melt, fg_em and full_efrt

# Get count of GOA-only EM EFP Vessels for the cost_params 
trawl_efp_goa_only <- length(na.omit(unlist(unname(
  setDT(readxl::read_xlsx("source_data/2024 EM EFP Vessel List_NMFS.xlsx", col_names = F))[-c(1:3), 7]))))

# Effort Prediction for 2023/2024. Use this for applying EFP opt-in probability and  bootstrapped populations for cost estimates
# In Vision 2024 ADP/Data folder:   https://drive.google.com/file/d/1YrICOVzkn6bvYyW55LeJospAeh0mfMgQ/view?usp=drive_link
load("source_data/effort_prediction.rdata") # Loads effort_strata, effort_year, and efp_prob  

# Load the ADFG statistical area shapefile. '../' is needed for Rmarkdown to climb into parent folders.
stat_area_sf <- st_read(
  dsn = "source_data/ADFG_Stat_Area_shapefile/PVG_Statewide_2001_Present_GCS_WGS1984.shp", quiet = T) %>%
  select(STAT_AREA) %>%
  st_transform(crs = 3467)

# Load the Alaska map sf objects
load("source_data/ak_shp.rdata")      # shp_land, shp_nmfs, and shp_centroids added to global

#===============#
## Functions ----
#===============#

source("analyses/allocation_evaluation/functions.R")

# TODO Add this to functions.R. Also used by effort_prediction_exploration.R
allo_prox <- function(box_def, allo_lst, cost_params, budget, max_budget, index_interval = 0.001, range_var = 1) { 
  
  # TODO I think this function could be faster. index_interval should be replaced by a level of resolution that we want 
  # to achieve for the index afforded, and rates should be adjusted for each stratum to achieve that. Initialize 
  # proximity/cv_scaling/index range with coarse resolution of rates, if needed subdivide those until a particular
  # resolution of indices is acquired, find the cost of each of those indices, hone in on a particular range, repeatedly
  # adjusting rates until the specified resolution of indices is acquired. 
  
  # Have to do this by year, so feed the data one year at a time
  group_cols <- c(box_def$params$year_col, box_def$params$stratum_cols)
  stratum_cols <- box_def$params$stratum_cols
  year_col <- box_def$params$year_col
  
  year_vec <- unique(box_def$strata_n_dt$ADP)
  
  # TODO FOR NOW, OMIT ZERO and EM_TRW as we will not allocate to either in 2024
  box_def$strata_n_dt <- box_def$strata_n_dt[!(STRATA %like% "ZERO|EM_TRW")]
  box_def$dt_out <- box_def$dt_out[!(STRATA %like% "ZERO|EM_TRW")]
  box_def$box_smry <- box_def$box_smry[!(names(box_def$box_smry) %like% "ZERO|EM_TRW")]
  
  year_res <- vector(mode = "list", length = length(year_vec))
  
  for(i in year_vec) {
    
    box_def_sub.prox.range <- calculate_interspersion_gs(box_def, sample_rate_vec = c(0.0001, seq(0.05, 1, by = 0.001)), omit_strata = "ZERO" )$ispn_dt[ADP == i]
    # Calculate index for each stratum
    box_def_sub.prox.range[
    ][, n := SAMPLE_RATE * STRATA_N
    ][, FPC := (STRATA_N - n) / STRATA_N
    ][, CV_SCALING := sqrt(FPC * (1/n))
    ][, INDEX := ISPN * (1 - CV_SCALING)][is.na(INDEX), INDEX := 0]
    setorderv(box_def_sub.prox.range, c(stratum_cols, "INDEX"))
    # Approximate the costs of a range of indices 
    index_vec <- seq(0, 1, by = 0.025)
    index_vec_rates_costs <- lapply(
      index_vec, 
      function(x) {
        res <- box_def_sub.prox.range[, .SD[findInterval(x, INDEX)], by = c(box_def$params$stratum_cols)]
        stratum_column <- apply(res[, ..stratum_cols], 1, paste, collapse = "-")
        res[, STRATUM_COL := stratum_column]
        res[, INDEX := x]
        index_cost <- calculate_cost_prox(res, cost_params, allo_lst, max_budget) # this is the most this index would cost
        if( nrow(index_cost) > 0 ) res[, INDEX_COST := index_cost$INDEX_COST]
        res
      }
    )
    
    # Omit any indices that go over the maximum budget
    index_costs <- sapply(index_vec_rates_costs, function(x) unique(x$INDEX_COST))
    for(j in seq_along(index_costs)) {
      if( is.null(index_costs[[j]])) {
        index_costs <- unlist(index_costs[1:(j - 1)])
        break()
      } else if (j > 1) {
        if( index_costs[[j]] < index_costs[[j - 1]]) {
          index_costs <- unlist(index_costs[1:(j - 1)])
          break()
        }
      }
    }
    
    # Find the range of indices to explore
    index_near_budget <- findInterval(budget, index_costs)
    index_range <- index_vec[c(index_near_budget - range_var, index_near_budget + 1)]  # I can afford an index somewhere in this range
    # Get all stratum names
    strata_dt <- unique(box_def$strata_n_dt[, ..stratum_cols])
    prox_by_stratum_lst <- vector(mode = "list", length = nrow(strata_dt))
    # Calculate proximity for each stratum using a focused range of sample rates
    for(k in 1:nrow(strata_dt)) {
      # k <- 1
      
      stratum_year <- paste0(i, ".", paste(strata_dt[k], collapse = "." ))
      # Make a new box definition specific to the stratum of focus
      box_stratum <- list(
        box_smry = box_def$box_smry[stratum_year],
        strata_n_dt = box_def$strata_n_dt,
        params = box_def$params
      )
      # Find the stratum's range of sample rates
      sample_range <- sapply(
        index_vec_rates_costs[c(index_near_budget - range_var, index_near_budget + 1)],             # FIXME I have to do +2 instead of +1. findInterval always underestimates?
        function(x) x[strata_dt[k], on = c(box_def$params$stratum_cols), SAMPLE_RATE]
      )
      # box_res <- copy(box_stratum); omit_strata <- NULL; sample_rate_vec <- seq(0.5, 575, by = 0.0001)
      # Now, we go back calculating rates ever 0.0001 here.
      prox_by_stratum <- calculate_interspersion_gs(box_stratum, sample_rate_vec = seq(sample_range[1], sample_range[2], by = 0.0001))$ispn_dt
      prox_by_stratum[
      ][, n := SAMPLE_RATE * STRATA_N
      ][, FPC := (STRATA_N - n) / STRATA_N
      ][, CV_SCALING := sqrt(FPC * (1/n))
      ][, INDEX := ISPN * (1 - CV_SCALING)]
      prox_by_stratum_lst[[k]]  <- prox_by_stratum
      
    }
    prox_by_list_dt <- rbindlist(prox_by_stratum_lst)
    
    # find the common range of indices
    # Find range if INDEX that is common to all strata x ADP
    prox_by_list_dt[, as.list(setNames(range(INDEX), c("MIN", "MAX"))), by = c(stratum_cols)]
    
    index_range_afforded <- prox_by_list_dt[
    ][, .(MIN = min(INDEX), MAX = max(INDEX)), by = group_cols
    ][, .(MIN = max(MIN),  MAX = min(MAX)), by = year_col]
    
    prox_by_list_dt <- prox_by_list_dt[, .SD[between(INDEX, index_range_afforded$MIN, index_range_afforded$MAX )], by = c(stratum_cols)]
    
    # I can set index_interval to 0.0001 to really get the closes to affording the budget. Does take 10x longer...
    prox_index_search <- seq(round(index_range_afforded$MIN,3), round(index_range_afforded$MAX,3), by = index_interval)
    index_costs2 <- lapply(prox_index_search, function(x) {
      x1 <- data.table(INDEX = x)
      x2 <- prox_by_list_dt[, .SD[x1, on = .(INDEX), roll = "nearest"], by = c(stratum_cols)]
      stratum_column <- apply(x2[, ..stratum_cols], 1, paste, collapse = "-")
      x2$STRATUM_COL <- stratum_column
      x2
    })
    # Calculate the cost of each index
    index_costs_vec <- sapply(index_costs2, function(x) {
      calculate_cost_prox(x, cost_params, allo_lst, max_budget)$INDEX_COST
    })
    
    # Find the index that is closest to the budget
    closest_to_budget <- findInterval(budget, unlist(index_costs_vec))
    out <- index_costs2[[closest_to_budget]]
    out[, INDEX_COST := unlist(index_costs_vec)[closest_to_budget]]
    year_res[[which(year_vec == i)]] <- out
  }
  
  # Return the allocated rates, collasping the list of rates by year
  rbindlist(year_res)
  
}

#=======================#
## Monitoring  Costs ----
#=======================#

# Derived from: https://docs.google.com/spreadsheets/d/1kcdLjq2Ck4XJBYP0EhrQpuknRgtQFt01LN3xUaCg7cI/edit?usp=sharing
# Monitoring cost models are applyed by ob_cost(), emfg_cost(), and emtrw_cost() functions
# Set all parameters involving monitoring costs

cost_params <- list(
  
  OB = list(
    day_rate_intercept          = 1870.4466666667,    # To calculate the sea day cost
    day_rate_slope              =   -0.2263733333,    # To calculate the sea day cost
    travel_day_rate             =  423.7867560407     # Expected cost of travel per day
  ),
  
  EMFG = list(
    emfg_v                      = fg_em[FLAG == "NONE", .N],   # Size of fixed-gear EM vessel pool. [179 for 2023. UPDATE FOR 2024]
    cost_per_vessel             = 5679.9002264045,
    cost_per_review_day         =  150.3237858616
  ),
  
  EMTRW = list(
    emtrw_goa_v                 =   trawl_efp_goa_only,  # Number of EM_TRW vessels that fish exclusively in the GOA. 
    trip_to_plant_factor        =    3.8059361492,    # Used to predict plant days from trips
    amortized_equipment_per_VY  = 4100.7124800000,    # Per (Vessel x Year) amortized EM equipment install costs for GOA-only vessels
    equipment_upkeep_per_VY     = 4746.0398955882,    # Per (Vessel x Year) EM equipment maintenance cost for GOA-only vessels
    review_day_rate             =   27.9918948996,    # Per sea day cost for EM compliance review
    plant_day_rate              =  908.2225000000     # Per plant day cost for shoreside monitoring by observers
  )
)

#================#
## Parameters ----
#================#

budget_lst <- list(4.8e6 + 1.019e6)  # Budget of $5,819,000, same as in the Draft ADP

# Number of bootstrap iterations
bootstrap_iter <- 1000
sim_iter <- 1000

# Setting for flextable outputs
set_flextable_defaults(font.family = "Times New Roman", font.size = 12) 

#======================================================================================================================#
# Determine Rates for 2024 ----
#======================================================================================================================#

# For the 2024 ADP, we will use fishing effort from the prior year (2022-Oct-1 to 2023-Sep-30 or something), and using
# our fishing effort prediction for 2023, we will sample without replacement to generate new bootstrapped populations
# to which we will allocate. We will take the average allocated rate across the bootstrapped populations as the rate 
# to allocate in 2024.

#=======================================#
## Generate Bootstrapped Populations ----
#=======================================#

# Subset prior 1 year of fishing effort
pc_effort_sub <- pc_effort_dt[TRIP_TARGET_DATE >= "2022-10-01" & TRIP_TARGET_DATE <= "2023-09-30"]
pc_effort_sub[, ADP := 2024]

# Remake trips_melt for the subset
# trips_melt_sub <- trips_melt[TRIP_ID %in% unique(pc_effort_sub$TRIP_ID)]
# trips_melt_sub[, ADP := 2024]

#==============================#
### Sample with replacement ----
#==============================#

# Use the outputs of effort_prediction.R, specifically 'effort_strata[ADP == 2024]', to predict the total number of
# trips to sample for each stratum

sample_N <- copy(effort_strata[ADP == 2024])[
][, STRATA := gsub("_BSAI", "-BSAI", STRATA)
][, STRATA := gsub("_GOA", "-GOA", STRATA)
][, STRATA := gsub("_EFP", "", STRATA)
][!(STRATA %like% "EM|ZERO"), STRATA := paste0("OB_", STRATA)
][, N := round(TOTAL_TRIPS)]
sample_N <- sample_N[, .(STRATA, N)]

setkey(pc_effort_sub, STRATA)
pc_effort_lst <- split(pc_effort_sub, by = "STRATA")

# Make sure names and ordering are the same
if(!identical(names(pc_effort_lst), sample_N$STRATA)) stop("Stratum names/order are not the same!")

# Initialize bootstrap list
swor_boot_lst <- vector(mode = "list", length = bootstrap_iter)
# Run the bootstrap loop. Takes ~4.5 hours to complete 1000 bootstrap iterations.
set.seed(12345)
for(k in seq_len(bootstrap_iter)) {
  # k <- 1
  cat(k, ", ")
  
  # Bootstrap using adp_strata_N to sample each stratum's population size size
  swor_bootstrap.effort <- rbindlist(Map(
    function(prior, strata_N) {
      # prior <- pc_effort_lst[[5]]; strata_N <- sample_N$N[5]
      
      # Create vector of TRIP_IDs
      trip_ids <- unique(prior$TRIP_ID)
      # How many times does prior effort go into future effort?
      prior_vs_future <- floor(strata_N / length(trip_ids))
      # What number of trips should be sampled without replacement?
      swr_n <- strata_N - (length(trip_ids) * prior_vs_future)
      # Create dt of trip_ids
      sampled_trip_ids <- data.table(
        TRIP_ID = c(
          # Repeat trip_id prior_vs_future times
          rep(trip_ids, times = prior_vs_future), 
          # Sample without replacement using swr_n
          sample(trip_ids, size = swr_n, replace = F)
        )
      )
      sampled_trip_ids[, I := .I]
      # Bring in each trip's data
      bootstrap_sample <- prior[sampled_trip_ids, on = .(TRIP_ID), allow.cartesian = T]
    }, 
    prior = pc_effort_lst,
    strata_N = sample_N$N
  ))
  
  # Re-assign trip_id so that we can differentiate trips sampled multiple times
  swor_bootstrap.effort[, TRIP_ID := .GRP, keyby = .(ADP, STRATA, BSAI_GOA, TRIP_ID, I)]
  if(uniqueN(swor_bootstrap.effort$TRIP_ID) != sum(sample_N$N)) stop("Count of TRIP_IDs doesn't match!")
  
  # Apply the Trawl EM EFP opt-in probability, move those that 'opt-out' into OB_TRW-GOA
  em_trw_id <- unique(swor_bootstrap.effort[STRATA == "EM_TRW-GOA", TRIP_ID ])
  # Randomly sample vessels as opting in (TRUE) or out (FALSE) of the EFP. We will use the 'expected' number of trips
  # opting out rather than allowing it to be stochastic so that STRATA_N does not vary between iterations.
  trw_em_opt_out_N <- round(sample_N[STRATA == "EM_TRW-GOA", N] * efp_prob[COVERAGE_TYPE == "PARTIAL", 1 - EFP_PROB])
  trw_em_opt_out_id <- sample(em_trw_id, size = trw_em_opt_out_N)
  swor_bootstrap.effort[TRIP_ID %in% trw_em_opt_out_id, ':=' (POOL = "OB", STRATA = "OB_TRW-GOA")]

  # Define boxes of bootstrapped effort
  swor_bootstrap.box <- define_boxes_gs(
    swor_bootstrap.effort, c(2e5, 2e5), time = c("week", 1, "TRIP_TARGET_DATE", "LANDING_DATE"),
    year_col = "ADP", stratum_cols = c("STRATA"), geom = F, ps_cols = c("GEAR"))
  # Calculate each stratum's mean trip duration of bootstrapped effort
  swor_bootstrap.allo_lst <- list(effort = unique(swor_bootstrap.effort[, .(ADP, STRATA, BSAI_GOA, TRIP_ID, DAYS)])[
  ][, .(STRATA_N = uniqueN(TRIP_ID), TRP_DUR = mean(DAYS)), keyby = .(ADP, STRATA)])
  
  # Calculate proximity at 15% sample rate (function is still called interspersion)
  # swor_bootstrap.prox <- calculate_interspersion_gs(swor_bootstrap.box, sample_rate_vec = sample_rate_15)$ispn_dt
  
  # Calculate rates afforded with the specified budget
  swor_bootstrap.rates <- allo_prox(swor_bootstrap.box, swor_bootstrap.allo_lst, cost_params, budget_lst[[1]], max_budget = 7e6, index_interval = 0.0001)
  # Capture results of iteration
  swor_boot_lst[[k]] <- list(
    rates = swor_bootstrap.rates,
    strata_N = sample_N
  )
  
}

if(F) save(swor_boot_lst, file = "results/swor_boot_lst.rdata")
# load(file = "results/swor_boot_lst.rdata")

# Extract the results from each iteration
boot_dt <- rbindlist(lapply(swor_boot_lst, "[[", "rates"), idcol = "BOOT_ITER")

#=============================#
# Determine Rates for 2024 ----
#=============================#

# Resulting rates have very little variability, nice.
ggplot(boot_dt, aes(x = STRATA, y = SAMPLE_RATE)) + geom_violin(draw_quantiles = 0.5) + facet_wrap(.~ STRATA, scales = "free") + stat_summary(geom = "point", fun = mean)
boot_dt[, sd(SAMPLE_RATE), keyby = STRATA]
boot_dt[, diff(range(SAMPLE_RATE)), keyby = STRATA] # Range of sample rates are basically within 1%

ggplot(boot_dt, aes(x = STRATA, y = SAMPLE_RATE)) + geom_violin(draw_quantiles = 0.5) + stat_summary(geom = "point", fun = mean) + labs(x = "Stratum", y = "Sample Rate") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) + geom_hline(yintercept = 0)

# Calculate the rates to use as the mean across iterations. Also calculate average proximity (ISPN) and cv_scaling metrics
rates_adp_2024_final <- boot_dt[, lapply(.SD, mean), .SDcols = c("SAMPLE_RATE", "n", "ISPN", "CV_SCALING", "INDEX"), keyby = .(ADP, STRATA, STRATA_N)]

# Checking that new allo_prox function does the same thing as older allocation functions, just faster
if(F) {
  
  # Define boxes. ps_cols = "GEAR" forces neighboring within a stratum to be gear-specific for the `FIXED` gear strata.
  system.time(box_def <- define_boxes_gs(
    pc_effort_sub, c(2e5, 2e5), time = c("week", 1, "TRIP_TARGET_DATE", "LANDING_DATE"),
    year_col = "ADP", stratum_cols = c("STRATA"), dmn_cols = c("BSAI_GOA", "GEAR"), geom = T, ps_cols = "GEAR"))
  
  pc_effort_sub.allo_lst <- list(effort = unique(pc_effort_sub[, .(ADP, STRATA, BSAI_GOA, TRIP_ID, DAYS)])[
  ][, .(STRATA_N = uniqueN(TRIP_ID), TRP_DUR = mean(DAYS)), keyby = .(ADP, STRATA)])
  
  # Here's what I get with allo_prox
  system.time(rates <- allo_prox(box_def, pc_effort_sub.allo_lst, cost_params, budget_lst[[1]], max_budget = 7e6, index_interval = 0.0001))
  
  
  # And what I get with my old functions
  # Calculate proximity
  sample_rate_vec <- seq(from = 0.0001, to = 0.9950, by = 0.0001) 
  system.time({
    proximity <- calculate_interspersion_gs(box_def, sample_rate_vec, omit_strata = c("ZERO", "EM_TRW-GOA"))
    # Calculate index
    fixed_fmp.prox_index <- calculate_index2(proximity, cost_params, pc_effort_sub.allo_lst, max_budget = 7e6)
    # Determine rates afforded
    fixed_fmp.rates <- rbindlist(lapply(budget_lst, function(x) cbind(BUDGET = x, prox_rates_from_budget2(fixed_fmp.prox_index, budget = x))))
  })
  
  # 14.6s for new function (index interval 0.0001, 25.44 for older ones. Not a huge difference
  
  rates             # 0.8831
  fixed_fmp.rates   # 0.883028, higher degree of accuracy? basically the same? This higher resolution is not true due to rolling join?
  
  sum(rates$SAMPLE_RATE)
  sum(fixed_fmp.rates$SAMPLE_RATE) # Lower by 0.001, or 1% total
  
  fixed_fmp.rates
  # Tentatively:
  # 12.62% in OB_FIXED-GOA, 24% in OB_TRW-GOA. 
  # In FGEM, get 277 samples instead of 303.6 from 30% across the board, so overall ~10% fewer HDs to review
  
  
  
}


#=============================#
# Determine Costs for 2024 ----
#=============================#

# Here, we will bootstrap with replacement again, but fishing effort as number of trips is allowed to vary according to 
# the variation returned by the effort prediction model. This way, we can get the distribution of realized costs upon a
# variety of potential outcomes.


# Incorporate variability of total fishing effort into this round of bootstrapping so that realized costs reflect this
# variability. This time, use effort_year[ADP == 2024]
sample_N_plus_variation <- copy(sample_N)
# Calculate proportions of strata
sample_N_plus_variation[, STRATUM_PROP := N / sum(N)]

# INITIALIZE NORMAL DISTRIBUTION OF VARIANCE HERE SO WE CAN ENSURE IT'S NOT SKEWED
# TODO Move these to functions script
library(e1071)              # used by normal_vector
normal_vector <- function(n, mean, sd, tol, alpha, seed){
  
  set.seed(seed)
  attempt <- 0
  # Initialize test results
  mean_test <- F; median_test <- F; norm_test <- F; kurt_test <- F; skew_test <- F
  
  # Repeatedly sample from normal distribution until an 'ideal' normal distribution is constructed
  while(any(!c(mean_test, median_test, norm_test, kurt_test, skew_test))) {
    attempt <- attempt + 1
    norm_vec <- rnorm(n = n, mean = mean, sd = sd)                   # Sample vector of GVF
    mean_test <- abs(diff(c(mean(norm_vec), mean))/mean) < tol                   # Test if mean of distribution is within tol of target mean
    median_test <- abs(diff(c(median(norm_vec), mean))/mean) < tol               # Test if median of distribution is within tol of target mean
    norm_test <- shapiro.test(norm_vec)$p.value > alpha                          # Test if ensure the distribution is normal
    kurt_test <- abs(kurtosis(norm_vec, type = 2)) < 0.2                         # For now, use 0.2 as cutoffs. Can be smaller with larger samples.
    skew_test <- abs(skewness(norm_vec)) < 0.2
  }
  cat(paste("GVF vector sampling completed after", attempt, "attempts.\n"))
  return(norm_vec)
}

# Build a vector of total fishing effort including variation from effort prediction model. The normal_vector() function
# tries to ensure that the vector of variable fishing effort sampled from the normal distribution is centered on the
# intended mean, is roughly normal, not skewed or kurtotic, etc.
total_N_with_variation <- normal_vector(n = bootstrap_iter, mean = effort_year[ADP == 2024, TOTAL_TRIPS], sd = effort_year[ADP == 2024, se], tol = 0.001, alpha = 0.05, seed = 12345)
# hist(total_N_with_variation); abline(v = mean(effort_year[ADP == 2024, TOTAL_TRIPS])); abline(v = mean(total_N_with_variation), col = "red")

# Initialize bootstrap list
costs_boot_lst <- vector(mode = "list", length = bootstrap_iter)
# Run the bootstrap loop
set.seed(12345)
for(k in seq_len(bootstrap_iter)) {
  # k <- 1
  
  # Perform garbage collection every 10 iterations
  if( k %% 10 == 0 ) invisible(gc())
  
  cat(paste0(k, ", "))
  
  # Incorporate variability in total N
  # Sample from a normal distribution to determine how much total STRATA_N should vary.
  # for total STRATA_N, use sum(round(effort_strata[ADP == 2024, round(TOTAL_TRIPS)]))
  new_total_N <- total_N_with_variation[k]
  # Apply stratum proportions to the new total trips.
  new_sample_N <- copy(sample_N_plus_variation)[, N := round(STRATUM_PROP * new_total_N)][, STRATUM_PROP := NULL][]
  
  # Bootstrap using adp_strata_N to sample each stratum's population size size
  costs_bootstrap.effort <- rbindlist(Map(
    function(prior, strata_N) {
      # prior <- pc_effort_lst[[5]]; strata_N <- sample_N$N[5]
      
      # Create vector of TRIP_IDs
      trip_ids <- unique(prior$TRIP_ID)
      # How many times does prior effort go into future effort?
      prior_vs_future <- floor(strata_N / length(trip_ids))
      # What number of trips should be sampled without replacement?
      swr_n <- strata_N - (length(trip_ids) * prior_vs_future)
      # Create dt of trip_ids
      sampled_trip_ids <- data.table(
        TRIP_ID = c(
          # Repeat trip_id prior_vs_future times
          rep(trip_ids, times = prior_vs_future), 
          # Sample without replacement using swr_n
          sample(trip_ids, size = swr_n, replace = F)
        )
      )
      sampled_trip_ids[, I := .I]
      # Bring in each trip's data
      bootstrap_sample <- prior[sampled_trip_ids, on = .(TRIP_ID), allow.cartesian = T]
    }, 
    prior = pc_effort_lst,
    strata_N = new_sample_N$N
  ))
  
  # Re-assign trip_id so that we can differentiate trips sampled multiple times
  costs_bootstrap.effort[, TRIP_ID := .GRP, keyby = .(ADP, STRATA, BSAI_GOA, TRIP_ID, I)]
  if(uniqueN(costs_bootstrap.effort$TRIP_ID) != sum(new_sample_N$N)) stop("Count of TRIP_IDs doesn't match!")
  
  # Apply the Trawl EM EFP opt-in probability, move those that 'opt-out' into OB_TRW-GOA
  em_trw_id <- unique(costs_bootstrap.effort[STRATA == "EM_TRW-GOA", TRIP_ID ])
  # Randomly sample vessels as opting in (TRUE) or out (FALSE) of the EFP. This sampling will be stochastic, so the
  # number of trips that 'opt-out' will vary randomly.
  trw_em_opt_out_id <- em_trw_id[runif(length(em_trw_id)) < efp_prob[COVERAGE_TYPE == "PARTIAL", 1 - EFP_PROB]]
  costs_bootstrap.effort[TRIP_ID %in% trw_em_opt_out_id, ':=' (POOL = "OB", STRATA = "OB_TRW-GOA")]

  # Calculate mean trip duration of each stratum
  costs_bootstrap.allo_lst <- unique(costs_bootstrap.effort[, .(ADP, STRATA, BSAI_GOA, TRIP_ID, DAYS)])[
  ][, .(STRATA_N = length(unique(TRIP_ID)), TRP_DUR = mean(DAYS)), keyby = .(ADP, STRATA)]
  # Apply the selection rates for the ADP to the bootstrapped fishing effort
  costs_bootstrap.allo_lst[, SAMPLE_RATE := rates_adp_2024_final[costs_bootstrap.allo_lst, SAMPLE_RATE, on = .(STRATA)]]
  # Add in some columns so calculate_cost_prox can calculate the total cost
  costs_bootstrap.allo_lst[, INDEX := 1]
  costs_bootstrap.allo_lst[, STRATUM_COL := STRATA]
  costs_bootstrap.allo_lst <- list(effort = costs_bootstrap.allo_lst)
  
  # This is the cost incurred on average (assuming perfect deployment)
  #costs_expected <- calculate_cost_prox(costs_bootstrap.allo_lst$effort[!is.na(SAMPLE_RATE)], cost_params, costs_bootstrap.allo_lst, max_budget = 7e6)
  
  # Here, simulate sampling to get the distribution of costs incurred
  costs_effort_summary <- unique(costs_bootstrap.effort[, .(POOL, TRIP_ID, STRATA, DAYS)])
  costs_effort_summary[, SAMPLE_RATE := rates_adp_2024_final[costs_effort_summary, SAMPLE_RATE, on = .(STRATA)]]
  #costs_effort_summary[, STRATA_N := uniqueN(TRIP_ID), keyby = .(STRATA)]
  costs_effort_summary <- costs_effort_summary[!is.na(SAMPLE_RATE)]
  # Simulate trip selection. Takes only a few seconds for 1,000 iterations, but seems to occasionally get hung up for a few seconds?
  costs_effort_summary_N <- length(unique(costs_effort_summary$TRIP_ID))
  # For each ODDS simulation iteration, simulate random number selection for each trip
  odds_RN_lst <- lapply(1:sim_iter, function(x) runif(n = costs_effort_summary_N))
  
  sim_lst <- vector(mode = "list", length = sim_iter)
  for(h in seq_len(sim_iter) ) {
    # if(h %% 10 == 0) cat(paste0(h, ", "))
    
    sim_dat <- copy(costs_effort_summary)#[!is.na(SAMPLE_RATE)]
    sim_dat$RN <- odds_RN_lst[[h]] 
    #sim_dat[, RN := runif(.N, 0, 1)]
    sim_n_dat <- sim_dat[RN < SAMPLE_RATE, .(n = length(unique(TRIP_ID)), d = sum(DAYS)), keyby = .(STRATA)]
    
    sim_costs <- list(
      OB = ob_cost( sim_n_dat, cost_params, sim = T),
      EMFG = emfg_cost( sim_n_dat, cost_params, sim = T),
      EMTRW = emtrw_cost( sim_n_dat, cost_params, sim = T)
    )
    
    # Compile the results from each ODDS simulation iteration
    sim_lst[[h]] <- list(
      TOTAL_COST = sum(c(
        sim_costs$OB$OB_TOTAL,
        sim_costs$EMFG$EMFG_TOTAL,
        sim_costs$EMTRW$EMTRW_TOTAL
      )),
      METHOD_COST = list(
        OB = mean(sim_costs$OB$OB_TOTAL),
        EMFG = mean(sim_costs$EMFG$EMFG_TOTAL)
      )
    )
  }
  
  # Compile the cost results from each bootstrap population iteration
  costs_boot_lst[[k]] <- list(
    TOTAL_COST_SIM = sapply(sim_lst, "[[", "TOTAL_COST"),    # Grab the total cost from each iteration
    METHOD_COST_SIM = sapply(sim_lst, "[[", "METHOD_COST"),
    #TOTAL_COST_EXP = costs_expected$INDEX_COST,
    #sim_res = sim_lst,
    new_total_N = new_total_N 
  )
  
  rm(new_sample_N, costs_bootstrap.effort, costs_bootstrap.allo_lst, odds_RN_lst, costs_effort_summary, sim_dat, sim_costs, sim_lst)
  
  # Realized costs of fgem
  # hist(sapply(sim_lst, function(x) x[["METHOD_COST"]][["EMFG"]][["EMFG_TOTAL"]]))
  # mean(sapply(sim_lst, function(x) x[["METHOD_COST"]][["EMFG"]][["EMFG_TOTAL"]]))  # 1.21M on average
}

if(F) save(costs_boot_lst, file = "results/costs_boot_lst.rdata")
# load(file = "results/costs_boot_lst.rdata")


# 
# # TODO SAVING THE TOTAL_N WOULD BE GOOD TO MAKE SURE OUR DISTRIBUTION OF EFFORT IS CENTERED WHERE IT SHOULD BE
# 
# names(costs_boot_lst[[1]])
# 
# costs_boot_lst[[1]]$sim_res[[1]]
# sapply(lapply(costs_boot_lst, "[[", "TOTAL_COST_SIM"), mean)  # for each population, average across ODDS iterations
# # sapply(costs_boot_lst, "[[", "TOTAL_COST_EXP")
# sapply(costs_boot_lst, "[[", "new_total_N")  # Can also just grab total_N_with_variation, but at least it's saved
# hist(total_N_with_variation)
# 
# #hist(sapply(lapply(costs_boot_lst, "[[", "TOTAL_COST_SIM"), mean) - sapply(costs_boot_lst, "[[", "TOTAL_COST_EXP")); abline(v = 0, col = "red")
# # The simulated costs are biased a bit lower than the 'expected' costs, which is good to know. We'll use the simulated costs, however.
# 
# # Taking the average random sampling from each bootstrapped population, we get this:
# hist(sapply(lapply(costs_boot_lst, "[[", "TOTAL_COST_SIM"), mean)); abline(v = budget_lst[[1]], col = "red")
# # Our costs are biased a little on the low end, which is fine.
# # Average across ODDS iterations for each bootstrap population, then take average:
# mean(sapply(lapply(costs_boot_lst, "[[", "TOTAL_COST_SIM"), mean))
# 
# 
# # If we ignore the population averages, and plot all iterations across all populations, we get something a little more normally distribyted
# # and centered on our budget
# hist(unlist(lapply(costs_boot_lst, "[[", "TOTAL_COST_SIM")), breaks = 20); abline(v = budget_lst[[1]], col = "red")
# # draw quantiles
# abline(v = quantile(unlist(lapply(costs_boot_lst, "[[", "TOTAL_COST_SIM")), probs = c(0.025, 0.25, 0.5, 0.75, 0.975)), col = "blue")
# abline(v = mean(unlist(lapply(costs_boot_lst, "[[", "TOTAL_COST_SIM"))), col = "purple")
# 
# 
# sum(unlist(lapply(costs_boot_lst, "[[", "TOTAL_COST_SIM")) < budget_lst[[1]]) / (bootstrap_iter * sim_iter) # 50% of outcomes below budget
# mean(unlist(lapply(costs_boot_lst, "[[", "TOTAL_COST_SIM")))

#======================================================================================================================#
# THINGS TO MAKE FOR FINAL ADP ----
#======================================================================================================================#

# Make a table with 'pretty' stratum names
strata_tbl <- unique(pc_effort_sub[, .(POOL, STRATA)])
strata_tbl[
][, Pool := fcase(
  STRATA %like% "OB_", "At-sea Observer",
  STRATA %like% "EM_FIXED", "Fixed-gear EM",
  STRATA %like% "EM_TRW", "Trawl EM (EFP)",
  STRATA == "ZERO", "Zero")
][, Stratum := STRATA  
][, Stratum := gsub("-", " ", Stratum)
][, Stratum := gsub("FIXED", "Fixed-gear", Stratum)
][, Stratum := gsub("TRW", "Trawl", Stratum)
][, Stratum := gsub("ZERO", "Zero", Stratum)
][, Stratum := gsub("OB|EM", "", Stratum)
][, Stratum := gsub("_", "", Stratum)]


# Main part of document ( trips, rates in full and partial coverage)
## Table 2.

#========================================================================#
## Table B-2. Budgets, vessels in Draft vs Final for partial coverage ----
#========================================================================#

# Load data objects used for the 2024 Draft ADP (draft rates were calculated using 2022 effort)
# https://drive.google.com/file/d/13AZTKA7VyPP0ZW9rM8JRTyDBdclFW8Bu/view?usp=drive_link

# Load rates and summary of 2024 Draft ADP
load("analyses/draft_rates/rates_adp_2024_draft.rdata")

table_b2.draft <- copy(rates_adp_2024_draft)[, .(POOL, STRATA, DRAFT = V)]
table_b2.final <- pc_effort_sub[, .(FINAL = uniqueN(PERMIT)), keyby = .(POOL, STRATA)]
table_b2 <- table_b2.draft[table_b2.final, on = .(POOL, STRATA)]
table_b2 <- strata_tbl[table_b2, on = .(POOL, STRATA)]
table_b2[, GROUP := fcase(
  POOL == "OB", paste(Pool, Stratum),
  POOL == "EM", paste(POOL, Stratum),
  POOL == "ZE", Pool)]
table_b2[, POOL := factor(POOL, levels = c("OB", "EM", "ZE"))]
setorder(table_b2, POOL, Stratum)

# Funding. For Draft, budget was $5,896,623
funding <- rbind(
  data.table(GROUP = "Partial Coverage Monitoring Budget ($)"),
  data.table(GROUP = "Total", DRAFT = 5.819e6, FINAL = budget_lst[[1]]),
  fill = T)
# Combine funding and vessel counts
table_b2 <- rbind(
  funding, 
  rbind(
    data.table(GROUP = "Vessels participating (partial coverage)"), 
    table_b2[, .(GROUP, DRAFT, FINAL)],
    fill = T))
# Format as flextable
table_b2_flex <- table_b2 %>% flextable() %>% 
  compose(i = ~ !is.na(DRAFT), value = as_paragraph("\t", .) , use_dot = T) %>%
  colformat_num(j = 2:3, digits = 0) %>%
  bold(i = ~ is.na(DRAFT)) %>%
  bold(part = "header") %>%
  hline(i = ~ GROUP == "Total") %>%
  hline(i = ~ is.na(DRAFT)) %>%
  set_header_labels(values = c("", "Draft 2024 ADP", "Final 2024 ADP")) %>% 
  autofit()
table_b2_flex

#================================================================#
## Table B-3. Predicted N, sample rate, n, d (including FULL) ----
#================================================================#

# This will use the result of the bootstraps where STRATA_N did not vary.

#===============#
# FIXME For now, redoing the bootstrap. However, in the first bootstrap above, replace the STRATA_N object with the
# updated STRATA_N and D data.table! 
day_count_lst <- vector(mode = "list", length = bootstrap_iter)
set.seed(12345)
for(k in seq_len(bootstrap_iter)) {
  # k <- 1
  cat(k, ", ")
  
  # Bootstrap using adp_strata_N to sample each stratum's population size size
  swor_bootstrap.effort <- rbindlist(Map(
    function(prior, strata_N) {
      # prior <- pc_effort_lst[[5]]; strata_N <- sample_N$N[5]
      
      # Create vector of TRIP_IDs
      trip_ids <- unique(prior$TRIP_ID)
      # How many times does prior effort go into future effort?
      prior_vs_future <- floor(strata_N / length(trip_ids))
      # What number of trips should be sampled without replacement?
      swr_n <- strata_N - (length(trip_ids) * prior_vs_future)
      # Create dt of trip_ids
      sampled_trip_ids <- data.table(
        TRIP_ID = c(
          # Repeat trip_id prior_vs_future times
          rep(trip_ids, times = prior_vs_future), 
          # Sample without replacement using swr_n
          sample(trip_ids, size = swr_n, replace = F)
        )
      )
      sampled_trip_ids[, I := .I]
      # Bring in each trip's data
      bootstrap_sample <- prior[sampled_trip_ids, on = .(TRIP_ID), allow.cartesian = T]
    }, 
    prior = pc_effort_lst,
    strata_N = sample_N$N
  ))
  
  # Re-assign trip_id so that we can differentiate trips sampled multiple times
  swor_bootstrap.effort[, TRIP_ID := .GRP, keyby = .(ADP, STRATA, BSAI_GOA, TRIP_ID, I)]
  if(uniqueN(swor_bootstrap.effort$TRIP_ID) != sum(sample_N$N)) stop("Count of TRIP_IDs doesn't match!")
  
  # Apply the Trawl EM EFP opt-in probability, move those that 'opt-out' into OB_TRW-GOA
  em_trw_id <- unique(swor_bootstrap.effort[STRATA == "EM_TRW-GOA", TRIP_ID ])
  # Randomly sample vessels as opting in (TRUE) or out (FALSE) of the EFP. We will use the 'expected' number of trips
  # opting out rather than allowing it to be stochastic so that STRATA_N does not vary between iterations.
  trw_em_opt_out_N <- round(sample_N[STRATA == "EM_TRW-GOA", N] * efp_prob[COVERAGE_TYPE == "PARTIAL", 1 - EFP_PROB])
  trw_em_opt_out_id <- sample(em_trw_id, size = trw_em_opt_out_N)
  swor_bootstrap.effort[TRIP_ID %in% trw_em_opt_out_id, ':=' (POOL = "OB", STRATA = "OB_TRW-GOA")]
  
  boot_smry <- unique(swor_bootstrap.effort[, .(ADP, POOL, STRATA, TRIP_ID, DAYS)])
  
  # Capture results of iteration
  day_count_lst[[k]] <- boot_smry[, .(N = uniqueN(TRIP_ID), D = sum(DAYS)), keyby = .(ADP, POOL, STRATA)]

}
day_count_dt <- rbindlist(day_count_lst, idcol = "BOOT_ITER")
#===============#

# Summarize N and D across all bootstraps. N did not vary in the bootstrap for allocation
table_b3.final <- day_count_dt[, lapply(.SD, mean), .SDcols = c("N", "D"), keyby = .(POOL, STRATA)]
table_b3.final <- strata_tbl[table_b3.final, on = .(POOL, STRATA)]

# Merge in allocated rates and hardcode rates for ZERO and EM_TRW-GOA
table_b3.final[
][, r := 100 * rates_adp_2024_final[table_b3.final, SAMPLE_RATE, on = .(STRATA)]
][STRATA == "EM_TRW-GOA", r := 33.33
][STRATA == "ZERO", r := 0]
# Calculate sampled trips and days
table_b3.final[
][, n := N * r/100
][, d := D * r/100
][, c("POOL", "STRATA", "D") := NULL]
setcolorder(table_b3.final, c("Pool", "Stratum", "N", "n", "d", "r"))

table_b3_final_full <- full_efrt[
][START >= "2022-10-01" & END <= "2023-09-30"
][STRATA != "EM_TRW_EFP_BSAI", STRATA := "FULL"        # FIXME For some reason these full coverage trips are in STRATA == "EM_TRW_EFP_GOA GOA"
][, .(DAYS = as.numeric(max(START, END) - min(START, END)) + 1), by = .(POOL, STRATA, TRIP_ID)
][, .(N = uniqueN(TRIP_ID), D = sum(DAYS)), by = .(POOL, STRATA)]
table_b3_final_full[
][, r := 1
][, ':=' (n = round(N * r), d = round(D * r))
][, ':=' (r = r * 100, D = NULL)]
# Make the names prettier
table_b3_final_full[, Pool := c("Full Coverage")]
table_b3_final_full[, Stratum := c("Full", "Trawl BSAI")]
table_b3_final_full[, c("POOL", "STRATA") := NULL]
table_b3.final <- rbind(
  table_b3.final,
  table_b3_final_full
)

# Add total rows for each Pool
table_b3.final <- table_b3.final[, rbind(.SD, data.table(
  Stratum = "Total", N = sum(N), n = sum(n), d = sum(d), r = weighted.mean(r, N))),
  by = .(Pool)]
# Set order of Pool
table_b3.final[, Pool := factor(Pool, levels = c("At-sea Observer", "Fixed-gear EM", "Trawl EM (EFP)", "Zero", "Full Coverage"))]
setorder(table_b3.final, Pool)

##   [Draft ADP]
# In the 2024 Draft ADP, We didn't account for the EFP_PROB.
table_b3.draft <- copy(rates_adp_2024_draft)[, .(POOL, STRATA, N, D, r = SAMPLE_RATE * 100) ]
table_b3.draft <- strata_tbl[table_b3.draft, on = .(POOL, STRATA)]
table_b3.draft[, n := N * r/100]
table_b3.draft[, d := D * r/100]
table_b3.draft[, c("POOL", "STRATA", "D") := NULL]
setcolorder(table_b3.draft, c("Pool", "Stratum", "N", "n", "d", "r"))
# Add total rows for each Pool
table_b3.draft <- table_b3.draft[, rbind(.SD, data.table(
  Stratum = "Total", N = sum(N), n = sum(n), d = sum(d), r = weighted.mean(r, N))),
  by = .(Pool)]
# Set order of Pool
table_b3.draft[, Pool := factor(Pool, levels = c("At-sea Observer", "Fixed-gear EM", "Trawl EM (EFP)", "Zero"))]
setorder(table_b3.draft, Pool)

# Combine Draft and Final 
table_b3_dat <- rbind(
  rbind(data.table(Pool = "Draft 2024 ADP"), table_b3.draft, fill = T),
  rbind(data.table(Pool = "Final 2024 ADP"), table_b3.final, fill = T)
)

# Summaries by Component (used in executive summary)
table_b3.final[Stratum == "Total"][, .(N = sum(N), n = round(sum(n)), d = round(sum(d))), by = .(Component = ifelse(Pool == "Full Coverage", "Full", "Partial"))]

# Create flextable object
table_b3_flex <- table_b3_dat %>% flextable() %>% 
  compose(i = 1, j = 2, part = "header", value = as_paragraph(., " (", as_i("h"), ")" ), use_dot = T) %>%
  compose(i = 1, j = 3:5, part = "header", value = as_paragraph(as_i(.), as_i(as_sub("h"))), use_dot = T) %>%
  compose(i = 1, j = 6, part = "header", value = as_paragraph(as_i(.), as_i(as_sub("h")), " (%)"), use_dot = T) %>%
  bold(i = ~ Stratum == "Total", j = 2:6, part ="body") %>%
  bold(i = ~ is.na(Stratum), j = 1, part ="body") %>%
  colformat_double(j = c(3:5), digits = 0) %>%
  colformat_double(j = 6, digits = 2) %>%
  merge_v(j = 1) %>%
  valign(j = 1, valign = "top") %>%
  hline(i = ~ is.na(Stratum)) %>%
  hline(i = ~ Stratum == "Total") %>%
  hline(i = ~ c((Stratum == "Total")[-1], FALSE), j = 2:6, border = fp_border(style = "dotted")) %>%
  autofit() %>%
  fix_border_issues()
table_b3_flex

#================================================================#
## Table 2. Summary of rates and sampled trips
#================================================================#

# Just re-arrange what used for Table B-3.
table_2 <- copy(table_b3.final)
table_2[, Component := ifelse(Pool %like% "Full", "Full Coverage", "Partial Coverage")]
table_2 <- table_2[, .(Component, Pool, Stratum, N, r = round(r, 2), n = round(n))]

table_2_flex <- table_2 %>% flextable() %>% 
  # compose(i = 1, j = 2, part = "header", value = as_paragraph(., " (", as_i("h"), ")" ), use_dot = T) %>%
  # compose(i = 1, j = 3:5, part = "header", value = as_paragraph(as_i(.), as_i(as_sub("h"))), use_dot = T) %>%
  # compose(i = 1, j = 6, part = "header", value = as_paragraph(as_i(.), as_i(as_sub("h")), " (%)"), use_dot = T) %>%
  set_header_labels(values = c("Component", "Pool", "Stratum", "Total Number of Expected Trips", "Selection Rate (%)", "Number of Trips Expected to be Monitored")) %>%
  bold(i = ~ Stratum == "Total", j = 2:6, part ="body") %>%
  bold(i = ~ is.na(Stratum), j = 1, part ="body") %>%
  colformat_double(j = c(4:6), digits = 0) %>%
  merge_v(j = 1:2) %>%
  valign(j = 1:2, valign = "top") %>%
  hline(i = ~ is.na(Stratum)) %>%
  hline(i = ~ Stratum == "Total") %>%
  hline(i = ~ c((Stratum == "Total")[-1], FALSE), j = 2:6, border = fp_border(style = "dotted")) %>%
  bold(i = 1, part = "header") %>% bold(j = 1:2, part = "body") %>%
  autofit() %>%
  fix_border_issues()

#========================================#
## Figure B-1 (flow chart of process) ----
#========================================#

# See output_figures/Figure_B1-Process-Diagram.svg and .png

#==========================================#
## Figure B-2 Plot of cost distribution ----
#==========================================#

costs_dt <- rbindlist(lapply(lapply(costs_boot_lst, "[[", "TOTAL_COST_SIM"), function(x) data.table(TOTAL_COST = x)), idcol = "SIM_ITER")
costs_dt[, ODDS_ITER := seq_len(.N), keyby = .(SIM_ITER)]
costs_dt_summary <- costs_dt[, .(X = unlist(  quantile(TOTAL_COST, c(0.025, 0.5, 0.975))))]
costs_dt_summary$QUANTILE = c(0.025, 0.5, 0.975)
costs_dt_summary$Y <- 7.5e4

# Describe the distribution
# Raw differences
round((costs_dt_summary$X - budget_lst[[1]]))
# Relative differences
round((costs_dt_summary$X - budget_lst[[1]]) / budget_lst[[1]] * 100,1)

figure_b2 <- ggplot(costs_dt) + 
  geom_histogram(aes(x = TOTAL_COST), fill = "gray", bins = 30) + 
  labs(x = "Partial coverage observer cost (millions of dollars)", y = "Number of ODDS iterations with this outcome") + 
  # 95% confidence
  geom_vline(data = costs_dt_summary[QUANTILE %in% c(0.025, 0.975)], aes(xintercept = X), color = "red", linetype = 2) + 
  geom_text(data = costs_dt_summary[QUANTILE %in% c(0.025, 0.975)], aes(x = X + c(1e4), y = Y, label = formatC(X, big.mark = ",", digits = 0, format = "d")), color = "red", angle = 90, vjust = 1) + 
  # Median
  geom_vline(data = costs_dt_summary[QUANTILE == 0.5], aes(xintercept = X), color = "blue", linetype = 2) + 
  geom_text(data = costs_dt_summary[QUANTILE == 0.5], aes(x = X, y = Y, label = formatC(X, big.mark = ",", digits = 0, format = "d")), color = "blue", angle = 90, vjust = -1, nudge_x = 1e4)  +
  # Budget
  geom_vline(xintercept = budget_lst[[1]], color = "purple", linetype = 2, linewidth = 1) + 
  annotate(geom = "text", x = budget_lst[[1]] + 1e4, y = 7.5e4, label = formatC(budget_lst[[1]], digits = 0, big.mark = ",", format = "d"), color = "purple", angle = 90, vjust = 1) + 
  scale_x_continuous(labels = function(x) formatC(x / 1e6, digits = 1, format = "f")) + 
  scale_y_continuous(labels = function(x) formatC(x, format = "d", big.mark = ",")) 


# Save Tables and Figures ----

# Save tables and figures for final_adp_tables_and_figures.Rmd
if(F) {
  save(
    table_b2_flex, table_b3_flex, table_2_flex,
     figure_b2,
     file = "results/final_adp_tables_and_figures_2024.rdata"
  )
  # Uploaded to Google drive: https://drive.google.com/file/d/1hDdNxy98E-DM8ZEfg4mJws_COkop6-vZ/view?usp=drive_link
}

# Save objects for use in the 2024 Annual Report
if(F) {
  save(
    # inputs
    pc_effort_sub, pc_effort_dt, # Fishing effort data (_sub being the subset used to represent 2024), _dt is prior
    effort_year, effort_strata,  efp_prob, # Fishing effort predictions and trawl EM EFP opt-out probability
    budget_lst, cost_params,     # Monitoring budget and monitoring cost parameters
    
    # outputs
    rates_adp_2024_final,  # Rates assigned to selected strata
    boot_dt,               # Results of effort bootstrap that led to allocation
    costs_dt,              # Results of effort bootstrap (with varying STRATA_N) and ODDS simulation
    
    file = "results/final_adp_2024_results.rdata"
  )
  # Uploaded to Google drive: https://drive.google.com/file/d/17lUFGYKTgD3WE1tOz3ZHRzDiUjWwejVd/view?usp=drive_link
}